{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From raw to structured \n",
    "\n",
    "### [Disentangling the cognitive, physical, and mental health sequelae of COVID-19.](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4008565)\n",
    "- Finding real messy raw data in the cognitive domain is not simple \n",
    "- For this example I chose the control dataset from the above paper which examined 12 established cognitive tests to examine intelligence in an online settings \n",
    "- It has two control datasets\n",
    "  - One with the actual cognitive test summary scores \n",
    "  - Another with an online questioner regarding various demographic questions\n",
    "- Our objective in this session is to create a joint table that contains information from both tables \n",
    "- The secondary objective is to combines everything we learned in the previous session and some additions \n",
    "- And we also need some interesting real life data to practice plotting for the next session and tomorrow \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by importing the pandas module\n",
    "- Notice that I am using a method called set_option to extend the display constrains imposed by pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max.columns\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option(\"display.max.columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following links to read the two datasets into a dataframe\n",
    "- Pandas has many ways to read and write tables into a dataframe in many formats \n",
    "- [for an exhaustive list](https://pandas.pydata.org/docs/user_guide/io.html)\n",
    "- Here we will use the `pd.read_csv` command that is able to download a url containing data in csv format and import it \n",
    "- Use the pd.read_csv command to complete the following code\n",
    "\n",
    "~~~\n",
    "tasks_url = 'https://tinyurl.com/bwfzme4r'\n",
    "demo_url = 'https://tinyurl.com/2s4cfah6'\n",
    "measures = \n",
    "demographics = \n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now use the `head` command to peak into the first five rows of the two datasets\n",
    "- You will see that tbe demographics is fine \n",
    "- In contrast, the measures headers are spanned over 3 rows (including the columns)\n",
    "- We want to tidy these column names to simplify data exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the column names \n",
    "#### Write a list comprehension for loop to go over the columns of the measures and strip the point suffix\n",
    "\n",
    "~~~python\n",
    "col_top = [ ___ for __ in ___ ]\n",
    "~~~\n",
    "\n",
    "#### Extract the first row of the measures dataframe as an array\n",
    "~~~python\n",
    "col_bottom = \n",
    "~~~\n",
    "\n",
    "#### Change the first two cells in col_top to `info` \n",
    "~~~python\n",
    "col_top___ = ___\n",
    "~~~\n",
    "\n",
    "#### Change the first two cells in col_bottom to `user` and `device` \n",
    "~~~python\n",
    "col_bottom___ = ___\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas has a MultiIndex class\n",
    "- We will use the `MultiIndex.from_tuples` method to convert our two sequences `col_top` and `col_bottom` to column name pairs\n",
    "- In three steps, \n",
    "  1. first use list comprehension and zip to merge the two lists in to a list of tuple pairs\n",
    "  2. Using that list create MultiIndex object and name the two columns [\"task\", \"measure\"]\n",
    "  3. Finally assign this index to the measures dataframe\n",
    "- \n",
    "\n",
    "~~~python\n",
    "multi_index = [ __ for __ in ___ ]\n",
    "index = pd.MultiIndex.from_tuples(multi_index, names=[\"task\", \"measure\"]) \n",
    "measures.columns = index\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the first two rows \n",
    "- Now use indexing to overwrite the first two rows of the measures data frame using the iloc method\n",
    "- And look at the results of your hard work using head or tail\n",
    "\n",
    "~~~python\n",
    "measures = \n",
    "measures.head()\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepend the word 'info' onto the demographics data frame\n",
    "- Before we can combine the two dataframes it will be useful to augment the columns index to be a multi-index also \n",
    "- There are many different ways to do that, in this example we will be using the function `concat`\n",
    "- It is used to concatenate (combine) together Series and Dataframes either by stacking them one over the other or stacking them side by side \n",
    "- By concatenating the a dictionary containing a Dataframe we are extending the index with one level \n",
    "\n",
    "~~~python \n",
    "demographics = pd.concat({'info': demographics},axis=1)\n",
    "~~~\n",
    "\n",
    "- Which is the same as writing this\n",
    "\n",
    "~~~python \n",
    "demographics.columns = pd.MultiIndex.from_tuples([('info',col) for col in demographics.columns])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almost final step we now can merge both dataframes with ease \n",
    "- The merge command is designed to merge together dataframes using ideas and concepts from SQL \n",
    "- In this context we will use an inner join which gives us only users that have some tasks completed and some questioner data \n",
    "- In this class, this will be our primary data set, which will enable us to investigate various analytical tasks using a data set that is as close to reality as possible while still being simple enough to fit in this timeframe. \n",
    "  \n",
    "![](https://res.cloudinary.com/practicaldev/image/fetch/s--07Go4Ldi--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/i/u4rx9tnq7ei4fstlafec.png)\n",
    "\n",
    "~~~python \n",
    "df = pd.merge(measures.set_index(('info','user')),\n",
    "              demographics.set_index(('info','user')),\n",
    "              how='inner',\n",
    "              left_index=True,\n",
    "              right_index=True)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If everything worked as planned...\n",
    "- Then we now have 13 high level headings each aggregating all the relevant information together \n",
    "- Next session we will start exploring how to use that to our advantage to produce both summary tables and preliminary rapid visualizations \n",
    "- For now, just run the following command to examine the demographics of the joint dataset \n",
    "\n",
    "~~~python\n",
    "df[['info']]\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make it usable in other notebooks we need to be able to save this file \n",
    "- Pandas supports multiple output types \n",
    "- I am using the pickle format for two reasons: \n",
    "  - It preserves the datatypes and multi-index heading \n",
    "\n",
    "~~~python \n",
    "df.to_pickle('12_tasks.pkl')\n",
    "df = pd.read_pickle('12_tasks.pkl')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step create a reproducible function that captures this process and can be adapted to other projects with minor changes\n",
    "\n",
    "~~~python\n",
    "def download_data():\n",
    "    tasks_url = 'https://tinyurl.com/bwfzme4r'\n",
    "    demo_url = 'https://tinyurl.com/2s4cfah6'\n",
    "    measures = pd.read_csv(tasks_url)\n",
    "    demographics = pd.read_csv(demo_url)\n",
    "    return measures,demographics\n",
    "\n",
    "def fix_measures_columns(measures):\n",
    "    col_top = [ v.split('.')[0] for v in measures.columns ]\n",
    "    col_bottom = measures.iloc[0,:].to_numpy()\n",
    "    col_top[0:2] = ['info','info']\n",
    "    col_bottom[0:2] = ('user','device')\n",
    "    multi_index = [tuple(v) for v in zip( col_top, col_bottom )]\n",
    "    measures.columns = pd.MultiIndex.from_tuples(multi_index, names=[\"task\", \"measure\"]) \n",
    "    measures = measures.iloc[2:,:]\n",
    "    return measures\n",
    "\n",
    "def load_clean_data():\n",
    "    import pandas as pd \n",
    "    from pathlib import Path\n",
    "    file_name = '12_tasks.pkl'\n",
    "    if Path(file_name).exists():\n",
    "        return df = pd.read_pickle(file_name)\n",
    "    else:\n",
    "        measures,demographics = download_data()\n",
    "        measures = fix_measures_columns(measures)\n",
    "        demographics = pd.concat({'info': demographics},axis=1)\n",
    "        df = pd.merge(measures.set_index(('info','user')),\n",
    "              demographics.set_index(('info','user')),\n",
    "              how='inner',\n",
    "              left_index=True,\n",
    "              right_index=True)\n",
    "        df.to_pickle(file_name)\n",
    "        return df\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links to expand your understanding \n",
    "\n",
    "For those interested in learning more...\n",
    "- [Merge, join, concatenate and compare](https://pandas.pydata.org/docs/user_guide/merging.html#merge-join-concatenate-and-compare)\n",
    "- [Input output tools in Pandas (text, CSV, HDF5, â€¦)](https://pandas.pydata.org/docs/user_guide/io.html#io-tools-text-csv-hdf5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "758785a5db8cea210020796a8d499f9bc3415c1f560a1a7f9f9e7309f37457cf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}