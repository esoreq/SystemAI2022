
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Basic terminology &#8212; System &amp; AI 2022</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://esoreq.github.io/SystemAI2022/class/week_05/01_classification_models.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="WEEK 05" href="00_overview.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/figures_LOGO.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">System & AI 2022</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../about/system_and_ai_2022.html">
   Introduction
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../about/bootcamp_intro.html">
   BOOT CAMP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../bootcamp/day_01/00_day_01_overview.html">
     DAY 01 - basics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/01_bash101.html">
       BASH 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/02_anaconda101.html">
       Anaconda environment 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/03_git101.html">
       Version control, git and github command line tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/04_jupyter_101.html">
       Jupyter notebooks 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/05_markdown_101.html">
       Markdown 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/06_homework.html">
       DAY 01 - HOMEWORK
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../bootcamp/day_02/00_day_02_overview.html">
     DAY 02 - Python
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/01_python_syntax_101.html">
       PYTHON SYNTAX 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/02_variables_101.html">
       PYTHON Basic Data Types
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/03_data_types.html">
       PYTHON Data operations 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/04_python_data_structures.html">
       PYTHON Data structures 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/05_programming_101.html">
       Python Programming 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/06_home_work.html">
       DAY 02 - HOMEWORK
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../bootcamp/day_03/00_day_03_overview.html">
     DAY 03 - Programming 101
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_03/01_python_functions_101.html">
       PYTHON FUNCTIONS 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_03/02_python_modules_101.html">
       PYTHON MODULES 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_03/03_anaconda_revisited.html">
       PYTHON ANACONDA 102
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_03/04_classes_in_python.html">
       PYTHON CLASSES 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_03/05_homework.html">
       DAY 03 - HOMEWORK
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../bootcamp/day_04/00_day_04_overview.html">
     DAY 04 - Numpy and Pandas 101
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_04/01_Numpy_data_structures.html">
       Numpy 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_04/02_Pandas_data_structures.html">
       Pandas 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_04/03_raw_to_tidy_with_pandas.html">
       From raw to structured
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_04/04_plotting_with_pandas.html">
       Plotting with pandas and Matplotlib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_04/05_homework.html">
       DAY 04 - HOMEWORK
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../bootcamp/day_05/00_day_05_overview.html">
     DAY 05 - Data visualisation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_05/01_visual_perception.html">
       Graphical Representations of Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_05/02_matplotlib_101.html">
       intro to matplotlib
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../about/setup.html">
   ⚙️ Course Setup
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week_01/00_overview.html">
   WEEK 01
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_01/01_reproducibility.html">
     What is Open and Reproducible Research?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_01/03_reproducibility_rules.html">
     Ten simple rules for reproducible research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_01/02_reproducibility_lab.html">
     Reproducibility lab
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week_02/00_overview.html">
   WEEK 02
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_02/02_data_cleaning_lab.html">
     DATA Cleaning 101
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_02/05_feature_engineering_lab.html">
     Feature Engineering and Feature Selection 101
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_02/03_outlier_detection_lab.html">
     We start by creating several subset datasets
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week_03/00_overview.html">
   WEEK 03
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_03/01_sklearn_101.html">
     Introducing Scikit-Learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_03/02_pca.html">
     Principal Component Analysis (PCA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_03/03_home_assignment.html">
     Home assignment
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week_04/00_overview.html">
   WEEK 04
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_04/01_regression_models.html">
     Let’s cover some more basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_04/02_assessing_performance.html">
     Resampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_04/03_brainage.html">
     Home assignment : Ageing and Structural VBM
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="00_overview.html">
   WEEK 05
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Basic terminology
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/class/week_05/01_classification_models.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        <a class="issues-button"
            href="https://esoreq.github.io/SystemAI2022//issues/new?title=Issue%20on%20page%20%2Fclass/week_05/01_classification_models.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Basic terminology
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-supervised-learning">
     What is Supervised Learning?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-common-procedures">
     Two common procedures
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-and-regression">
     Classification and Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-classification">
     What is classification?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#types-of-classification-tasks">
     Types of classification tasks
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-steps-involved-in-building-a-classification-model">
     Standard steps involved in building a classification model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#many-different-classification-algorithms">
     Many different classification algorithms
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distance-based">
       Distance-Based
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#statistical">
       Statistical
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#linear-model">
       Linear model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#kernel-models">
       Kernel models
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tree-based">
       Tree-Based
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ensemble-learners-harnessing-the-wisdom-of-crowds">
       Ensemble Learners - Harnessing the wisdom of crowds
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#what-is-a-weak-learner">
         What is a weak learner?
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#bagging-random-forest">
         Bagging - Random forest
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#boosting">
         Boosting
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-s-get-to-know-some-of-the-different-algorithms-using-toy-data">
     let’s get to know some of the different algorithms using toy data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compare-some-key-players-to-gain-intuition-to-how-they-work">
     Compare some key players to gain intuition to how they work
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-key-players">
     Some key players
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-likelihood-of-an-observation-to-be-part-of-class-a">
     What is the likelihood of an observation to be part of class a?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-about-a-noisy-dataset">
     What about a noisy dataset?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-about-non-linear-datasets">
     What about non-linear datasets?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#break">
     Break
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-do-we-need-to-approximate-classifiers-performance">
     Why do we need to approximate classifiers performance?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-we-estimate-classifiers-performance">
     How do we estimate classifiers performance
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#use-make-classification-to-create-synthetic-dataset">
     Use
     <code class="docutils literal notranslate">
      <span class="pre">
       make_classification
      </span>
     </code>
     to create synthetic dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-wrong-way-to-measure-classification-accuracy">
     The wrong way to measure classification accuracy
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-were-measuring-the-method-tendency-to-overfit">
     We were measuring the method tendency to overfit
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#another-problem-the-previous-example-had">
     Another problem the previous example had
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overfitting-causes">
     overfitting causes
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-validation-as-a-solution">
     Cross-validation as a solution
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-s-update-increase-dimensionality-our-example-and-estimate-performance">
     Let’s update (increase dimensionality) our example and estimate performance
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-data-is-both-high-dimensional-and-very-clean-let-s-add-some-noise">
     The data is both high-dimensional and very clean, let’s add some noise
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#now-we-will-compare-performance-on-train-vs-test-parts">
   Now we will Compare performance on train vs test parts
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-methods-are-much-more-sensitive-to-overfitting">
     Some methods are much more sensitive to overfitting
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reducing-dimensionality-in-decision-trees">
     Reducing dimensionality in decision trees
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-can-also-control-the-number-of-leaves-each-rule-has">
     We can also control the number of leaves each rule has
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#limitations-of-the-train-test-split-approach">
     Limitations of the train test split approach
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-validation-is-one-possible-solution-we-covered-last-week">
     Cross-validation is one possible solution we covered last week
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-we-missing">
     What are we missing?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confusion-matrix">
     Confusion matrix
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#beyond-accuracy">
   Beyond accuracy
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#macro-avg">
     macro avg
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weighted-avg">
     weighted avg
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#if-we-open-the-hood-of-our-models">
   If we open the hood of our models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#detection-error-tradeoff-and-receiver-operating-characteristic-curves">
     Detection error tradeoff and receiver operating characteristic curves
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Basic terminology</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Basic terminology
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-supervised-learning">
     What is Supervised Learning?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-common-procedures">
     Two common procedures
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-and-regression">
     Classification and Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-classification">
     What is classification?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#types-of-classification-tasks">
     Types of classification tasks
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-steps-involved-in-building-a-classification-model">
     Standard steps involved in building a classification model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#many-different-classification-algorithms">
     Many different classification algorithms
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distance-based">
       Distance-Based
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#statistical">
       Statistical
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#linear-model">
       Linear model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#kernel-models">
       Kernel models
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tree-based">
       Tree-Based
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ensemble-learners-harnessing-the-wisdom-of-crowds">
       Ensemble Learners - Harnessing the wisdom of crowds
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#what-is-a-weak-learner">
         What is a weak learner?
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#bagging-random-forest">
         Bagging - Random forest
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#boosting">
         Boosting
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-s-get-to-know-some-of-the-different-algorithms-using-toy-data">
     let’s get to know some of the different algorithms using toy data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compare-some-key-players-to-gain-intuition-to-how-they-work">
     Compare some key players to gain intuition to how they work
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-key-players">
     Some key players
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-likelihood-of-an-observation-to-be-part-of-class-a">
     What is the likelihood of an observation to be part of class a?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-about-a-noisy-dataset">
     What about a noisy dataset?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-about-non-linear-datasets">
     What about non-linear datasets?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#break">
     Break
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-do-we-need-to-approximate-classifiers-performance">
     Why do we need to approximate classifiers performance?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-we-estimate-classifiers-performance">
     How do we estimate classifiers performance
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#use-make-classification-to-create-synthetic-dataset">
     Use
     <code class="docutils literal notranslate">
      <span class="pre">
       make_classification
      </span>
     </code>
     to create synthetic dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-wrong-way-to-measure-classification-accuracy">
     The wrong way to measure classification accuracy
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-were-measuring-the-method-tendency-to-overfit">
     We were measuring the method tendency to overfit
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#another-problem-the-previous-example-had">
     Another problem the previous example had
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overfitting-causes">
     overfitting causes
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-validation-as-a-solution">
     Cross-validation as a solution
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-s-update-increase-dimensionality-our-example-and-estimate-performance">
     Let’s update (increase dimensionality) our example and estimate performance
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-data-is-both-high-dimensional-and-very-clean-let-s-add-some-noise">
     The data is both high-dimensional and very clean, let’s add some noise
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#now-we-will-compare-performance-on-train-vs-test-parts">
   Now we will Compare performance on train vs test parts
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-methods-are-much-more-sensitive-to-overfitting">
     Some methods are much more sensitive to overfitting
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reducing-dimensionality-in-decision-trees">
     Reducing dimensionality in decision trees
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-can-also-control-the-number-of-leaves-each-rule-has">
     We can also control the number of leaves each rule has
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#limitations-of-the-train-test-split-approach">
     Limitations of the train test split approach
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-validation-is-one-possible-solution-we-covered-last-week">
     Cross-validation is one possible solution we covered last week
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-we-missing">
     What are we missing?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confusion-matrix">
     Confusion matrix
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#beyond-accuracy">
   Beyond accuracy
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#macro-avg">
     macro avg
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weighted-avg">
     weighted avg
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#if-we-open-the-hood-of-our-models">
   If we open the hood of our models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#detection-error-tradeoff-and-receiver-operating-characteristic-curves">
     Detection error tradeoff and receiver operating characteristic curves
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="basic-terminology">
<h1>Basic terminology<a class="headerlink" href="#basic-terminology" title="Permalink to this headline">¶</a></h1>
<div class="section" id="what-is-supervised-learning">
<h2>What is Supervised Learning?<a class="headerlink" href="#what-is-supervised-learning" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Supervised Learning is all about learning from examples.</p></li>
<li><p>The basic idea is to identify meaningful patterns associated with some target label or value.</p></li>
<li><p>Then use these patterns to create a mapping function that is able to map unseen data to the trained value or label.</p></li>
</ul>
</div>
<div class="section" id="two-common-procedures">
<h2>Two common procedures<a class="headerlink" href="#two-common-procedures" title="Permalink to this headline">¶</a></h2>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p>Classification</p></th>
<th class="text-align:left head"><p>Regression</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>dependent variables</p></td>
<td class="text-align:left"><p>categorical</p></td>
<td class="text-align:left"><p>continuous</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Output</p></td>
<td class="text-align:left"><p>predicted Class</p></td>
<td class="text-align:left"><p>predicted value</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Performance</p></td>
<td class="text-align:left"><p>Accuracy</p></td>
<td class="text-align:left"><p>Deviation</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="classification-and-regression">
<h2>Classification and Regression<a class="headerlink" href="#classification-and-regression" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>In machine learning, both classification and regression are almost always static models.</p></li>
<li><p>In static models a distinction exists between two independent stages:</p>
<ol class="simple">
<li><p>The learning stage, when learners are trained on a training set</p></li>
<li><p>The performance stage where the model is tested using an independent test set.</p></li>
</ol>
</li>
</ul>
</div>
<div class="section" id="what-is-classification">
<h2>What is classification?<a class="headerlink" href="#what-is-classification" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Classification belongs to the category of supervised learning where matching targets (y) and input data (X) are used to train the model.</p></li>
<li><p>The goal of classification algorithms is to uncover a perfect relationship <span class="math notranslate nohighlight">\(f(X)=y\)</span></p></li>
<li><p>However, in reality data is noisy… therefore <span class="math notranslate nohighlight">\(f(X)=y +\epsilon\)</span></p></li>
<li><p>In Classification we use some computational method to train a model <span class="math notranslate nohighlight">\(\hat f(X) \approx f(X)\)</span>:</p>
<ul>
<li><p>Which means we try to find a mapping function (f)</p></li>
<li><p>Based on some input dataset (X)</p></li>
<li><p>To create discrete output labels (y)</p></li>
<li><p>That is close as possible to the hypothetical model <span class="math notranslate nohighlight">\(f(X)\)</span></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="types-of-classification-tasks">
<h2>Types of classification tasks<a class="headerlink" href="#types-of-classification-tasks" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Binary Classification: Classification task with two possible outcomes.</p>
<ul>
<li><p>Eg: Young/Old or Male/Female</p></li>
</ul>
</li>
<li><p>Multi-class classification: Classification with more than two classes.</p>
<ul>
<li><p>Eg: Visual/Auditory/Motor</p></li>
</ul>
</li>
<li><p>Multi-label classification: Classification task where each sample is mapped to a set of target labels (more than one class).</p>
<ul>
<li><p>Predicting whether a patient has one or more of the following disorders: depression, anxiety, schizophrenia, bipolar disorder, and substance abuse.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="standard-steps-involved-in-building-a-classification-model">
<h2>Standard steps involved in building a classification model<a class="headerlink" href="#standard-steps-involved-in-building-a-classification-model" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Initialize a classifier. Initialization commonly involves defining initial parameters specific to the type of classifier.</p></li>
<li><p>Train the classifier. All classifiers in scikit-learn are trained using the same fit(X, y) method. That fits the model to the training data (X) and the matching label (y).</p></li>
<li><p>Predict the target: Given an unseen observation X, the predict(X) returns the predicted label y.</p></li>
<li><p>Evaluate the classifier model using different strategies</p></li>
</ul>
</div>
<div class="section" id="many-different-classification-algorithms">
<h2>Many different classification algorithms<a class="headerlink" href="#many-different-classification-algorithms" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="https://scikit-learn.org/0.15/_images/plot_classifier_comparison_0011.png" />
It is out of the scope to cover all of these model families (and even this list is not exhaustive)</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn">Distance-Based</a> e.g. K Neighbors Classifier</p></li>
<li><p><a class="reference external" href="https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn">Statistical</a> - e.g naive-bayes</p></li>
<li><p><a class="reference external" href="https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python">linear model</a> - e.g. logistic regression</p></li>
<li><p><a class="reference external" href="https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python">Kernel</a> - e.g. Support vector machine</p></li>
<li><p><a class="reference external" href="https://www.datacamp.com/community/tutorials/decision-tree-classification-python">Tree-Based</a>  e.g. decision tree classifier</p></li>
<li><p><a class="reference external" href="https://www.datacamp.com/community/tutorials/ensemble-learning-python">Ensemble Learners</a> - bagging and boosting</p></li>
</ul>
<div class="section" id="distance-based">
<h3>Distance-Based<a class="headerlink" href="#distance-based" title="Permalink to this headline">¶</a></h3>
<p>The non-parametric algorithms assume that the geometric similarity between observations across the feature space relates to the response vector. These relationships enable us to categorize according to these patterns.</p>
<p>One of the most widely used and easiest non-parametric machine learning algorithms is the k-nearest-neighbour (k-NN) algorithm.</p>
<p>The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other. The model stores all the training data and for each new point it identifies the <code class="docutils literal notranslate"><span class="pre">k</span></code> neighbours and predicts the label using some heuristic (for classification it is the most common label or the mode)</p>
</div>
<div class="section" id="statistical">
<h3>Statistical<a class="headerlink" href="#statistical" title="Permalink to this headline">¶</a></h3>
<p>The assumption in these techniques is that the data follows a probability function that needs to be inferred from the dataset. The Gaussian naive Bayes model (Gaussian NB) is normally used with continuous data, where each class’ continuous value is assumed to follow a Gaussian distribution.</p>
</div>
<div class="section" id="linear-model">
<h3>Linear model<a class="headerlink" href="#linear-model" title="Permalink to this headline">¶</a></h3>
<p>Basically, a linear classifier makes a classification decision based on a linear combination of features. The use of such classifiers is very useful for most classification issues, and it is often considered the first choice for problems with multiple variables (features), as they reach accuracy levels comparable to non-linear classifiers with a lot less training time and effort.
In its simplest form, logistic regression uses a logistic function to model a binary dependent variable, though there are many more complex extensions available. Binomial logistic models have two possible outcomes, like pass/fail, that’s represented by two variables, “0” and “1”.</p>
</div>
<div class="section" id="kernel-models">
<h3>Kernel models<a class="headerlink" href="#kernel-models" title="Permalink to this headline">¶</a></h3>
<p>Kernel methods reach their name by using kernel functions, which enable the user to operate in a high-dimensional, implicit feature space without ever calculating its coordinates. These models perform pattern analysis based on a kernel function, which is a similarity function over pairs of data points.
The support vector machine uses a kernel to identify pairwise distances to establish a support vector group of observations that together construct a localised margin between classes in a way that maximizes the separation between classes.</p>
</div>
<div class="section" id="tree-based">
<h3>Tree-Based<a class="headerlink" href="#tree-based" title="Permalink to this headline">¶</a></h3>
<p>In these techniques, interpretable decision rules inferred from the training data are used to predict a target variable. Using a decision tree as a predictive model is widely used because it is easy to interpret (i.e., it provides a series of decisions that leads to the final classification result).</p>
</div>
<div class="section" id="ensemble-learners-harnessing-the-wisdom-of-crowds">
<h3>Ensemble Learners - Harnessing the wisdom of crowds<a class="headerlink" href="#ensemble-learners-harnessing-the-wisdom-of-crowds" title="Permalink to this headline">¶</a></h3>
<p>The basic idea is that one strong classifier is weaker than a committee of weak classifiers.  These models combine the predictions of several base estimators often reoffered to as weak learners built with a given learning algorithm to improve the results and robustness over a single estimator.</p>
<div class="section" id="what-is-a-weak-learner">
<h4>What is a weak learner?<a class="headerlink" href="#what-is-a-weak-learner" title="Permalink to this headline">¶</a></h4>
<p>“Weak learners” is a broad definition for any learning algorithm that is slightly better than randomly guessing</p>
</div>
<div class="section" id="bagging-random-forest">
<h4>Bagging - Random forest<a class="headerlink" href="#bagging-random-forest" title="Permalink to this headline">¶</a></h4>
<p>Bagging (Bootstrap Aggregation) – train each of the classifiers using a fresh training subset using random sample with replacement (effectively  reduce the variance in the dataset). An ensemble of decision trees makes up the random forest method. Several different decision trees are used, each created from a subset of features selected at random. Random forests are hard to interpret since they have multiple decision trees (in some cases, decisions are made by voting on seemingly contradictory facts). They perform well with high-dimensional data, however, and do not require any domain knowledge or complicated parameters.</p>
</div>
<div class="section" id="boosting">
<h4>Boosting<a class="headerlink" href="#boosting" title="Permalink to this headline">¶</a></h4>
<p>Boosting – each member of the committee is forced to classify a specific set of hard problems that the previous member struggled with. The idea is to train extremely shallow trees where in each step a portion of the feature space that the previous model performed poorly on is prioritised</p>
</div>
</div>
</div>
<div class="section" id="let-s-get-to-know-some-of-the-different-algorithms-using-toy-data">
<h2>let’s get to know some of the different algorithms using toy data<a class="headerlink" href="#let-s-get-to-know-some-of-the-different-algorithms-using-toy-data" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>We will start by creating the simplest 2D data-set</p></li>
<li><p>Look at several methods</p></li>
<li><p>Then make the data more complex</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span><span class="p">,</span><span class="n">make_blobs</span><span class="p">,</span><span class="n">make_moons</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">LinearDiscriminantAnalysis</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span><span class="n">RandomForestClassifier</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;bmh&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="nn">Input In [1],</span> in <span class="ni">&lt;cell line: 1&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span><span class="p">,</span><span class="n">make_blobs</span><span class="p">,</span><span class="n">make_moons</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;matplotlib&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="compare-some-key-players-to-gain-intuition-to-how-they-work">
<h2>Compare some key players to gain intuition to how they work<a class="headerlink" href="#compare-some-key-players-to-gain-intuition-to-how-they-work" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">cluster_std</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2021</span><span class="p">)</span>
<span class="n">y</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span><span class="o">=-</span><span class="mi">1</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span><span class="n">palette</span><span class="o">=</span><span class="s1">&#39;tab10&#39;</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x18e4c6980&gt;
</pre></div>
</div>
<img alt="../../_images/01_classification_models_19_1.png" src="../../_images/01_classification_models_19_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">2021</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">hue</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span><span class="n">palette</span><span class="o">=</span><span class="s1">&#39;tab10&#39;</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Train set&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">hue</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span><span class="n">palette</span><span class="o">=</span><span class="s1">&#39;tab10&#39;</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Test set&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Test set&#39;)
</pre></div>
</div>
<img alt="../../_images/01_classification_models_20_1.png" src="../../_images/01_classification_models_20_1.png" />
</div>
</div>
</div>
<div class="section" id="some-key-players">
<h2>Some key players<a class="headerlink" href="#some-key-players" title="Permalink to this headline">¶</a></h2>
<p>These models are very poorly parametrised to make their inner working apparent</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Logistic Regression&quot;</span> <span class="p">:</span><span class="n">LogisticRegression</span><span class="p">(),</span>
    <span class="s2">&quot;K-nearest neighbors&quot;</span> <span class="p">:</span>  <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="s2">&quot;Radial Basis Support Vector&quot;</span> <span class="p">:</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2022</span><span class="p">),</span>
    <span class="s2">&quot;Ada Boost&quot;</span><span class="p">:</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2022</span><span class="p">,</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="s2">&quot;Random Forest (Bagging+)&quot;</span><span class="p">:</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2022</span><span class="p">),</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="what-is-the-likelihood-of-an-observation-to-be-part-of-class-a">
<h2>What is the likelihood of an observation to be part of class a?<a class="headerlink" href="#what-is-the-likelihood-of-an-observation-to-be-part-of-class-a" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>We are interested in probabilities and all the models we will look at will have some way to predict labels and the likelihood value associated with that decision</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">decision_boundaries_plot</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span><span class="n">mdl</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">Y_test</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;PiYG&#39;</span><span class="p">,</span><span class="n">step_size</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
    <span class="n">extent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="mf">1.1</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="mf">1.1</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>
    <span class="n">fs1</span><span class="p">,</span> <span class="n">fs2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">extent</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">extent</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">step_size</span><span class="p">),</span>
                           <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">extent</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">extent</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">step_size</span><span class="p">))</span>
    <span class="n">mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">fs1</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">fs2</span><span class="o">.</span><span class="n">flatten</span><span class="p">()])</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">mesh</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">p</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">p</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">fs1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span> <span class="n">z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span><span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">,</span><span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span><span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">Y_test</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">title</span><span class="p">,</span><span class="n">mdl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">decision_boundaries_plot</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">mdl</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_25_0.png" src="../../_images/01_classification_models_25_0.png" />
</div>
</div>
</div>
<div class="section" id="what-about-a-noisy-dataset">
<h2>What about a noisy dataset?<a class="headerlink" href="#what-about-a-noisy-dataset" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">cluster_std</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2021</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">2021</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">hue</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span><span class="n">palette</span><span class="o">=</span><span class="s1">&#39;tab10&#39;</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Train set&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">hue</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span><span class="n">palette</span><span class="o">=</span><span class="s1">&#39;tab10&#39;</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Test set&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Test set&#39;)
</pre></div>
</div>
<img alt="../../_images/01_classification_models_27_1.png" src="../../_images/01_classification_models_27_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">title</span><span class="p">,</span><span class="n">mdl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">decision_boundaries_plot</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">mdl</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_28_0.png" src="../../_images/01_classification_models_28_0.png" />
</div>
</div>
</div>
<div class="section" id="what-about-non-linear-datasets">
<h2>What about non-linear datasets?<a class="headerlink" href="#what-about-non-linear-datasets" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="p">(</span><span class="mi">700</span><span class="p">,</span><span class="mi">300</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2020</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">2021</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">hue</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span><span class="n">palette</span><span class="o">=</span><span class="s1">&#39;tab10&#39;</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Train set&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">hue</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span><span class="n">palette</span><span class="o">=</span><span class="s1">&#39;tab10&#39;</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Test set&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Test set&#39;)
</pre></div>
</div>
<img alt="../../_images/01_classification_models_30_1.png" src="../../_images/01_classification_models_30_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">title</span><span class="p">,</span><span class="n">mdl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">decision_boundaries_plot</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">mdl</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_31_0.png" src="../../_images/01_classification_models_31_0.png" />
</div>
</div>
</div>
<div class="section" id="break">
<h2>Break<a class="headerlink" href="#break" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="why-do-we-need-to-approximate-classifiers-performance">
<h2>Why do we need to approximate classifiers performance?<a class="headerlink" href="#why-do-we-need-to-approximate-classifiers-performance" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Estimating classifiers performance is an essential tool for answering some of the following questions:</p>
<ul>
<li><p>Is there any useful information that can be used to classify events above random chance</p></li>
<li><p>Compare between information sources. I.e. which subsets of the data are more informative</p></li>
<li><p>Identify/rank important sources of information. I.e. are there individual features that contribute more information than other</p></li>
<li><p>Distinguish between global or local effects</p></li>
<li><p>Are the natural separations in the data linear, polynomial or non-linear</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="how-do-we-estimate-classifiers-performance">
<h2>How do we estimate classifiers performance<a class="headerlink" href="#how-do-we-estimate-classifiers-performance" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>There are several <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#metrics-and-scoring-quantifying-the-quality-of-predictions">ways</a>
the simplest is using some metric that evaluates the performance of each method</p></li>
<li><p>Among the many different metrics, the easiest to understand is classification accuracy</p></li>
<li><p>This measure simply counts the amount of accurately predicted labels and divides them by the total number of events</p></li>
</ul>
</div>
<div class="section" id="use-make-classification-to-create-synthetic-dataset">
<h2>Use <code class="docutils literal notranslate"><span class="pre">make_classification</span></code> to create synthetic dataset<a class="headerlink" href="#use-make-classification-to-create-synthetic-dataset" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>We previously used numpy to simulate data but sklearn has it’s own wrappers that do the same thing internally</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_repeated</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_informative</span><span class="o">=</span><span class="mi">1</span>
                           <span class="p">,</span><span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">class_sep</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2022</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_35_0.png" src="../../_images/01_classification_models_35_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;KNN&quot;</span>   <span class="p">:</span> <span class="n">KNeighborsClassifier</span><span class="p">(),</span>
          <span class="s2">&quot;LDA&quot;</span>   <span class="p">:</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">(),</span>
          <span class="s2">&quot;LOGC&quot;</span>  <span class="p">:</span> <span class="n">LogisticRegression</span><span class="p">(),</span>
          <span class="s2">&quot;SVC&quot;</span>   <span class="p">:</span> <span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
          <span class="s2">&quot;Lasso&quot;</span> <span class="p">:</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">),</span>
          <span class="s2">&quot;Boost&quot;</span> <span class="p">:</span> <span class="n">AdaBoostClassifier</span><span class="p">(),</span>
          <span class="s2">&quot;Bag&quot;</span>   <span class="p">:</span> <span class="n">RandomForestClassifier</span><span class="p">(),</span>
          <span class="s2">&quot;TREE&quot;</span>  <span class="p">:</span> <span class="n">DecisionTreeClassifier</span><span class="p">()}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="the-wrong-way-to-measure-classification-accuracy">
<h2>The wrong way to measure classification accuracy<a class="headerlink" href="#the-wrong-way-to-measure-classification-accuracy" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Let’s take the naive approach and understand the problems with it?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span><span class="n">classification_report</span>
<span class="n">n_models</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">bad_performance</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_models</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">name</span><span class="p">,</span><span class="n">mdl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">bad_performance</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">mdl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">),</span><span class="n">height</span><span class="o">=</span><span class="n">bad_performance</span><span class="p">);</span>  
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">()));</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">rect</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">patches</span><span class="p">):</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">rect</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">rect</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">rect</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span>
        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">bad_performance</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">);</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_38_0.png" src="../../_images/01_classification_models_38_0.png" />
</div>
</div>
</div>
<div class="section" id="we-were-measuring-the-method-tendency-to-overfit">
<h2>We were measuring the method tendency to overfit<a class="headerlink" href="#we-were-measuring-the-method-tendency-to-overfit" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>When we are creating a classification model, we aim to identify general/global patterns
that describe some real phenomena that differentiate between the two groups</p></li>
<li><p>Overfitting describes the situation where the model is uncovering local noise patterns that
are specific to the data-set but do not reflect a real effect</p></li>
<li><p>As a result, the model will be extremely accurate in the training stage but will fail when tested on unseen data</p></li>
<li><p>This example also highlights the sensitivity of non-parametric models (decision trees) to overfit data</p></li>
</ul>
</div>
<div class="section" id="another-problem-the-previous-example-had">
<h2>Another problem the previous example had<a class="headerlink" href="#another-problem-the-previous-example-had" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>We performed another mistake in the last example</p></li>
<li><p>A model is trained by maximizing its accuracy on the training dataset</p></li>
<li><p>However, performance is determined on its ability to perform well on unseen data.</p></li>
<li><p>In this case, overfitting reflects our model attempt to memorize the training data as opposed
to uncovering generalized patterns existing in the training data.</p></li>
</ul>
</div>
<div class="section" id="overfitting-causes">
<h2>overfitting causes<a class="headerlink" href="#overfitting-causes" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>High dimensional data is susceptible to <a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a></p></li>
<li><p>The larger the feature space, the more it is affected by local noise patterns</p></li>
<li><p>This problem of higher dimension is known as the Curse of Dimensionality.</p></li>
<li><p>To avoid overfitting, the needed data will need to grow exponentially as you increase the number of dimensions.</p></li>
<li><p>Also, small datasets are more sensitive to the effects of noise</p></li>
<li><p>Unfortunately we don’t usually have the luxury of gathering an extensive database in neuroscience.</p></li>
<li><p>We need a way to approximate real performance</p></li>
</ul>
</div>
<div class="section" id="cross-validation-as-a-solution">
<h2><a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-evaluating-estimator-performance">Cross-validation</a> as a solution<a class="headerlink" href="#cross-validation-as-a-solution" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Cross-validation is a set of techniques for assessing how the results of a statistical analysis will generalize to an independent data set.</p></li>
<li><p>The simplest way to cross-validate is to split the dataset into two parts (training and testing) and approximate performance only on the test-set</p></li>
</ul>
</div>
<div class="section" id="let-s-update-increase-dimensionality-our-example-and-estimate-performance">
<h2>Let’s update (increase dimensionality) our example and estimate performance<a class="headerlink" href="#let-s-update-increase-dimensionality-our-example-and-estimate-performance" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>The first plot shows the association between samples, and the square pattern is evidence for clustering</p></li>
<li><p>The second shows the association between features</p></li>
<li><p>Based on what we now know we would expect near-perfect classification on training set now</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">n_redundant</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">flip_y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_repeated</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">n_informative</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2022</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="../../_images/01_classification_models_42_1.png" src="../../_images/01_classification_models_42_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_models</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">bad_performance</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_models</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">name</span><span class="p">,</span><span class="n">mdl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">bad_performance</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">mdl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">),</span><span class="n">height</span><span class="o">=</span><span class="n">bad_performance</span><span class="p">);</span>  
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">()));</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">rect</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">patches</span><span class="p">):</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">rect</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">rect</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">rect</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span>
        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">bad_performance</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">);</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_43_0.png" src="../../_images/01_classification_models_43_0.png" />
</div>
</div>
</div>
<div class="section" id="the-data-is-both-high-dimensional-and-very-clean-let-s-add-some-noise">
<h2>The data is both high-dimensional and very clean, let’s add some noise<a class="headerlink" href="#the-data-is-both-high-dimensional-and-very-clean-let-s-add-some-noise" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>flip_y controls the fraction of samples whose class is assigned randomly.</p></li>
<li><p>Larger values introduce noise in the labels and make the classification task harder.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">n_redundant</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">flip_y</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">n_repeated</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">n_informative</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2020</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="../../_images/01_classification_models_45_1.png" src="../../_images/01_classification_models_45_1.png" />
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="now-we-will-compare-performance-on-train-vs-test-parts">
<h1>Now we will Compare performance on train vs test parts<a class="headerlink" href="#now-we-will-compare-performance-on-train-vs-test-parts" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Lets split the data to two parts and examine the model performance on the unseen part compared to the trained subset</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">n_models</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2020</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="n">performance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_models</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span><span class="s1">&#39;Test&#39;</span><span class="p">],</span><span class="n">index</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">name</span><span class="p">,</span><span class="n">mdl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">performance</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">name</span><span class="p">,:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">mdl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span>
                        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">mdl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">performance</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">bar_label</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)];</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_48_0.png" src="../../_images/01_classification_models_48_0.png" />
</div>
</div>
<div class="section" id="some-methods-are-much-more-sensitive-to-overfitting">
<h2>Some methods are much more sensitive to overfitting<a class="headerlink" href="#some-methods-are-much-more-sensitive-to-overfitting" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>It is clear that all models have a substantial decrease in accuracy when applied to the unseen subset</p></li>
<li><p>Each type of model has different ways of dealing with overfitting</p></li>
<li><p>For example in KNN increasing the number neighbors forces the model to take into account more points
when assigning a label to unseen data and as a result the learned pattern is less specific</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k_steps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2020</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="n">performance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">k_steps</span><span class="p">),</span><span class="mi">2</span><span class="p">)),</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span><span class="s1">&#39;Test&#39;</span><span class="p">],</span><span class="n">index</span> <span class="o">=</span> <span class="n">k_steps</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">k_steps</span><span class="p">):</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">performance</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">k</span><span class="p">,:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">tmp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span>
                        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">tmp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
    
<span class="n">ax</span> <span class="o">=</span> <span class="n">performance</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">bar_label</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)];</span>    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_50_0.png" src="../../_images/01_classification_models_50_0.png" />
</div>
</div>
</div>
<div class="section" id="reducing-dimensionality-in-decision-trees">
<h2>Reducing dimensionality in decision trees<a class="headerlink" href="#reducing-dimensionality-in-decision-trees" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>We saw that decision trees are susceptible to overfitting</p></li>
<li><p>One reason for that is that unless told otherwise, the algorithm will find some rule to split all leaves (samples)</p></li>
<li><p>We can constrain this behaviour by forcing depth threshold</p></li>
<li><p>This will result in a tree that only has the most informative dimensions</p></li>
<li><p>Examine the dramatic effect pruning (restricting the depth of the tree) the tree has on training accuracy</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">depth_steps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2020</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="n">performance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">depth_steps</span><span class="p">),</span><span class="mi">2</span><span class="p">)),</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span><span class="s1">&#39;Test&#39;</span><span class="p">],</span><span class="n">index</span> <span class="o">=</span> <span class="n">depth_steps</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">depth_steps</span><span class="p">):</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">performance</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">k</span><span class="p">,:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">tmp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span>
                            <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">tmp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
    
<span class="n">ax</span> <span class="o">=</span> <span class="n">performance</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">bar_label</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)];</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_52_0.png" src="../../_images/01_classification_models_52_0.png" />
</div>
</div>
</div>
<div class="section" id="we-can-also-control-the-number-of-leaves-each-rule-has">
<h2>We can also control the number of leaves each rule has<a class="headerlink" href="#we-can-also-control-the-number-of-leaves-each-rule-has" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>By default, each leaf is equivalent to one sample</p></li>
<li><p>In this context, a split rule can separate between two samples</p></li>
<li><p>This behaviour is precisely opposite to converging on general split points</p></li>
<li><p>And unsurprisingly it has a similar effect</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">min_samples_steps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">55</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2020</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="n">performance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">min_samples_steps</span><span class="p">),</span><span class="mi">2</span><span class="p">)),</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span><span class="s1">&#39;Test&#39;</span><span class="p">],</span><span class="n">index</span> <span class="o">=</span> <span class="n">min_samples_steps</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">min_samples_steps</span><span class="p">):</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">performance</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">k</span><span class="p">,:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">tmp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span>
                            <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">tmp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
    
<span class="n">ax</span> <span class="o">=</span> <span class="n">performance</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">bar_label</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)];</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_54_0.png" src="../../_images/01_classification_models_54_0.png" />
</div>
</div>
</div>
<div class="section" id="limitations-of-the-train-test-split-approach">
<h2>Limitations of the train test split approach<a class="headerlink" href="#limitations-of-the-train-test-split-approach" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Requires big datasets</p></li>
<li><p>Wasteful (a significant portion of the data is not used)</p></li>
<li><p>Is simple to manipulate (aka cherry-picking a random sample that is not representative of the reality)</p></li>
<li><p>Suffers from knowledge leakage (happens when the method’s parameters are optimised to the test set)</p></li>
<li><p>One solution calls for a 3-way splitting instead of the 2-way train/test</p>
<ul>
<li><p>Separating data into training, validation and test</p></li>
<li><p>Using the validation set for Parameter tweaking</p></li>
<li><p>Reporting performance based on the test set</p></li>
</ul>
</li>
<li><p>However, this method solves one problem but intensifies the rest.</p></li>
</ul>
</div>
<div class="section" id="cross-validation-is-one-possible-solution-we-covered-last-week">
<h2>Cross-validation is one possible solution we covered last week<a class="headerlink" href="#cross-validation-is-one-possible-solution-we-covered-last-week" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Cross-validation is a family of splitting concepts used to reduce overfitting effects
while leaning patterns from all the training data</p></li>
<li><p>The most basic approach is called k-fold where the k validation/training subsets of the data are created</p></li>
<li><p>Importantly, when using k-fold CV we need to make sure each test fold has enough samples</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">tick_args</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;axis&quot;</span> <span class="p">:</span> <span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="s2">&quot;which&quot;</span> <span class="p">:</span> <span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="s2">&quot;bottom&quot;</span> <span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
       <span class="s2">&quot;top&quot;</span> <span class="p">:</span> <span class="kc">False</span><span class="p">,</span><span class="s2">&quot;labelbottom&quot;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;labelleft&quot;</span><span class="p">:</span><span class="kc">False</span><span class="p">}</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2022</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">folds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="n">k</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span>
    <span class="n">folds</span><span class="p">[</span><span class="n">test_index</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>   
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span> 
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">folds</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span><span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="o">**</span><span class="n">tick_args</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;10-folds index matrix&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Folds (K=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">);</span>   
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_57_0.png" src="../../_images/01_classification_models_57_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2022</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">n_models</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2020</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="n">performance</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">c</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">name</span><span class="p">,</span><span class="n">mdl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,(</span><span class="n">ix_train</span><span class="p">,</span> <span class="n">ix_test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_train</span><span class="p">)):</span>
        <span class="n">inner_x</span><span class="p">,</span> <span class="n">inner_y</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">ix_train</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">ix_train</span><span class="p">]</span>
        <span class="n">mdl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">inner_x</span><span class="p">,</span> <span class="n">inner_y</span><span class="p">)</span>
        <span class="n">performance</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Model&#39;</span><span class="p">:</span><span class="n">name</span><span class="p">,</span><span class="s1">&#39;Fold&#39;</span><span class="p">:</span><span class="n">j</span><span class="p">,</span>
            <span class="s1">&#39;Train&#39;</span><span class="p">:</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">ix_train</span><span class="p">],</span><span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inner_x</span><span class="p">)),</span>
            <span class="s1">&#39;Val&#39;</span><span class="p">:</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">ix_test</span><span class="p">],</span><span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">ix_test</span><span class="p">])),</span>
            <span class="s1">&#39;Test&#39;</span><span class="p">:</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))}</span>
        <span class="n">c</span><span class="o">+=</span><span class="mi">1</span>
<span class="n">performance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">performance</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>        
<span class="n">performance</span> <span class="o">=</span> <span class="n">performance</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="s1">&#39;Fold&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;level_2&#39;</span><span class="p">:</span><span class="s1">&#39;CV&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;Score&#39;</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">performance</span><span class="p">,</span><span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;Model&#39;</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s1">&#39;CV&#39;</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;Score&#39;</span><span class="p">,</span>
            <span class="n">estimator</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">ci</span><span class="o">=</span><span class="s1">&#39;sd&#39;</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span><span class="n">errwidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">bar_label</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">padding</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)];</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_59_0.png" src="../../_images/01_classification_models_59_0.png" />
</div>
</div>
</div>
<div class="section" id="what-are-we-missing">
<h2>What are we missing?<a class="headerlink" href="#what-are-we-missing" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>We have some error around the accuracy</p></li>
<li><p>However, we are oblivious to how the models are performing internally</p></li>
<li><p>More specifically the accuracy measure we use is not providing us with any per class insight</p></li>
<li><p>Let’s dig deeper and examine (in the next section) the <a class="reference external" href="https://en.wikipedia.org/wiki/Confusion_matrix">confusion matrix</a></p></li>
</ul>
</div>
<div class="section" id="confusion-matrix">
<h2>Confusion matrix<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>The Confusion matrix allows visualization of the performance of classification methods</p></li>
<li><p>To understand this better let us take a step back and return to the train test split</p></li>
<li><p>The central part of the confusion matrix is composed of counting performance per class</p></li>
<li><p>In the case of the 2-way classification problem (i.e. binary) it is a 2 x 2 matrix</p></li>
<li><p>The diagonal represents samples classified correctly and the anti-diagonal those that were misclassified
<img alt="" src="../../_images/cm.png" /></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>


<span class="n">n_models</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2022</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="n">confusion</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">c</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">name</span><span class="p">,</span><span class="n">mdl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">confusion</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">test</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)),</span> 
                           <span class="n">train</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)))</span>  

    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_models</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">flat</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="s1">&#39;train&#39;</span><span class="p">],</span><span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.0f&#39;</span><span class="p">,</span><span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm_r&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Predicted&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Ground truth&#39;</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="n">name</span><span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Overfitting&#39;</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>    
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_models</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">flat</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="s1">&#39;test&#39;</span><span class="p">],</span><span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.0f&#39;</span><span class="p">,</span><span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm_r&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Predicted&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Ground truth&#39;</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="n">name</span><span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Generalisation&#39;</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_63_0.png" src="../../_images/01_classification_models_63_0.png" />
<img alt="../../_images/01_classification_models_63_1.png" src="../../_images/01_classification_models_63_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn</span>  <span class="kn">import</span> <span class="n">datasets</span>
<span class="n">breast_cancer</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">breast_cancer</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span><span class="n">columns</span><span class="o">=</span> <span class="n">breast_cancer</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">breast_cancer</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
<span class="n">n_models</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2022</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="n">report</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">confusion</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">c</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">name</span><span class="p">,</span><span class="n">mdl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">output_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">],</span> <span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">,</span><span class="s1">&#39;score&#39;</span><span class="p">]))</span>
    <span class="n">confusion</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">test</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)),</span> 
                           <span class="n">train</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)))</span>

<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_models</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">flat</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="s1">&#39;test&#39;</span><span class="p">],</span><span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.0f&#39;</span><span class="p">,</span><span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm_r&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Predicted&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Ground truth&#39;</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="n">name</span><span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Generalisation&#39;</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span> 
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_65_0.png" src="../../_images/01_classification_models_65_0.png" />
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="beyond-accuracy">
<h1>Beyond accuracy<a class="headerlink" href="#beyond-accuracy" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Precision_and_recall">Precision and recall</a></p>
<ul>
<li><p>Precision is the fraction of true positives divided by the total number of samples classified as positive (i.e. <span class="math notranslate nohighlight">\(TP/(TP+FP)\)</span>)</p></li>
<li><p>Recall (also known as sensitivity) is the fraction of true positives divided by the total number of actual positive samples.  (i.e. <span class="math notranslate nohighlight">\(TP/(TP+FN)\)</span>)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/F1_score">The F1 score</a> is the harmonic mean of the Precision and recall</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Bag</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">report</span><span class="p">)</span><span class="o">.</span><span class="n">xs</span><span class="p">(</span><span class="s1">&#39;Bag&#39;</span><span class="p">)</span>
<span class="n">Bag</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>precision</th>
      <th>recall</th>
      <th>f1-score</th>
      <th>support</th>
    </tr>
    <tr>
      <th>score</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.953271</td>
      <td>0.962264</td>
      <td>0.957746</td>
      <td>106.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.977528</td>
      <td>0.972067</td>
      <td>0.974790</td>
      <td>179.000000</td>
    </tr>
    <tr>
      <th>accuracy</th>
      <td>0.968421</td>
      <td>0.968421</td>
      <td>0.968421</td>
      <td>0.968421</td>
    </tr>
    <tr>
      <th>macro avg</th>
      <td>0.965400</td>
      <td>0.967166</td>
      <td>0.966268</td>
      <td>285.000000</td>
    </tr>
    <tr>
      <th>weighted avg</th>
      <td>0.968506</td>
      <td>0.968421</td>
      <td>0.968451</td>
      <td>285.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="section" id="macro-avg">
<h2>macro avg<a class="headerlink" href="#macro-avg" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>simply means taking the two class performance and averaging them</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mf">0.970588</span> <span class="o">+</span> <span class="mf">0.961749</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9661685
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="weighted-avg">
<h2>weighted avg<a class="headerlink" href="#weighted-avg" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>simply means taking the two class performance and averaging their relative support</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mf">0.970588</span><span class="o">*</span><span class="mi">106</span> <span class="o">+</span> <span class="mf">0.961749</span><span class="o">*</span><span class="mi">179</span><span class="p">)</span><span class="o">/</span><span class="mi">285</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9650364877192982
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weighted_avg</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">report</span><span class="p">)</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;score == &quot;weighted avg&quot;&#39;</span><span class="p">)</span>
<span class="n">weighted_avg</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>precision</th>
      <th>recall</th>
      <th>f1-score</th>
      <th>support</th>
    </tr>
    <tr>
      <th>model</th>
      <th>score</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>KNN</th>
      <th>weighted avg</th>
      <td>0.920314</td>
      <td>0.919298</td>
      <td>0.918293</td>
      <td>285.0</td>
    </tr>
    <tr>
      <th>LDA</th>
      <th>weighted avg</th>
      <td>0.976363</td>
      <td>0.975439</td>
      <td>0.975255</td>
      <td>285.0</td>
    </tr>
    <tr>
      <th>LOGC</th>
      <th>weighted avg</th>
      <td>0.944654</td>
      <td>0.943860</td>
      <td>0.944062</td>
      <td>285.0</td>
    </tr>
    <tr>
      <th>SVC</th>
      <th>weighted avg</th>
      <td>0.916151</td>
      <td>0.908772</td>
      <td>0.906131</td>
      <td>285.0</td>
    </tr>
    <tr>
      <th>Lasso</th>
      <th>weighted avg</th>
      <td>0.951625</td>
      <td>0.950877</td>
      <td>0.951055</td>
      <td>285.0</td>
    </tr>
    <tr>
      <th>Boost</th>
      <th>weighted avg</th>
      <td>0.961400</td>
      <td>0.961404</td>
      <td>0.961287</td>
      <td>285.0</td>
    </tr>
    <tr>
      <th>Bag</th>
      <th>weighted avg</th>
      <td>0.968506</td>
      <td>0.968421</td>
      <td>0.968451</td>
      <td>285.0</td>
    </tr>
    <tr>
      <th>TREE</th>
      <th>weighted avg</th>
      <td>0.917514</td>
      <td>0.915789</td>
      <td>0.916231</td>
      <td>285.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="if-we-open-the-hood-of-our-models">
<h1>If we open the hood of our models<a class="headerlink" href="#if-we-open-the-hood-of-our-models" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>By looking at the underlying relationship between observations and classes (by evaluating probability), we can gain some insight into the performance of the models (take this with a grain of salt)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_models</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">2022</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">title</span><span class="p">,</span><span class="n">mdl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2022</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">y</span><span class="o">*</span><span class="mf">0.1</span><span class="p">,</span><span class="n">y</span><span class="o">*</span><span class="mf">0.1</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,(</span><span class="n">ix_train</span><span class="p">,</span> <span class="n">ix_test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span>
        <span class="n">mdl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ix_train</span><span class="p">],</span><span class="n">y</span><span class="p">[</span><span class="n">ix_train</span><span class="p">])</span>
        <span class="n">y_hat</span><span class="p">[</span><span class="n">ix_test</span><span class="p">]</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ix_test</span><span class="p">])</span>
    <span class="n">jx</span><span class="p">,</span><span class="n">jy</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span><span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">jx</span><span class="p">,</span><span class="n">y_hat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">jy</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;PiYG&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_classification_models_74_0.png" src="../../_images/01_classification_models_74_0.png" />
</div>
</div>
<div class="section" id="detection-error-tradeoff-and-receiver-operating-characteristic-curves">
<h2>Detection error tradeoff and receiver operating characteristic curves<a class="headerlink" href="#detection-error-tradeoff-and-receiver-operating-characteristic-curves" title="Permalink to this headline">¶</a></h2>
<p>A ROC curve is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:</p>
<ol class="simple">
<li><p>True Positive Rate (TPR) is a synonym for recall :
$<span class="math notranslate nohighlight">\( TPR = \frac{TP}{TP+TN} \)</span>$</p></li>
<li><p>False Positive Rate (FPR) :
$<span class="math notranslate nohighlight">\( FPR = \frac{FP}{FP+TN} \)</span>$</p></li>
</ol>
<p>The detection error trade off graph plots the false rejection rate versus the false acceptance rate for binary classification systems.  With non-linear scaling of the x and y axes (or simply by logarithmic transformation), both yield trade off curves that are more linear than ROC curves, and which highlight the differences of importance most prominently in the critical operating region.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">plot_det_curve</span><span class="p">,</span><span class="n">plot_roc_curve</span>

<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">title</span><span class="p">,</span><span class="n">mdl</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">mdl</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plot_det_curve</span><span class="p">(</span><span class="n">mdl</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x1907610f0&gt;
</pre></div>
</div>
<img alt="../../_images/01_classification_models_76_1.png" src="../../_images/01_classification_models_76_1.png" />
</div>
</div>
<p>confusion[name]</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./class/week_05"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="00_overview.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">WEEK 05</p>
        </div>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Eyal Soreq<br/>
    
        &copy; Copyright 2021.<br/>
      <div class="extra_footer">
        <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>