
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Let’s cover some more basics &#8212; System &amp; AI 2022</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://esoreq.github.io/SystemAI2022/class/week_04/01_regression_models.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Resampling" href="02_assessing_performance.html" />
    <link rel="prev" title="WEEK 04" href="00_overview.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/figures_LOGO.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">System & AI 2022</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../about/system_and_ai_2022.html">
   Introduction
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../about/bootcamp_intro.html">
   BOOT CAMP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../bootcamp/day_01/00_day_01_overview.html">
     DAY 01 - basics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/01_bash101.html">
       BASH 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/02_anaconda101.html">
       Anaconda environment 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/03_git101.html">
       Version control, git and github command line tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/04_jupyter_101.html">
       Jupyter notebooks 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/05_markdown_101.html">
       Markdown 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_01/06_homework.html">
       DAY 01 - HOMEWORK
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../bootcamp/day_02/00_day_02_overview.html">
     DAY 02 - Python
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/01_python_syntax_101.html">
       PYTHON SYNTAX 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/02_variables_101.html">
       PYTHON Basic Data Types
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/03_data_types.html">
       PYTHON Data operations 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/04_python_data_structures.html">
       PYTHON Data structures 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/05_programming_101.html">
       Python Programming 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_02/06_home_work.html">
       DAY 02 - HOMEWORK
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../bootcamp/day_03/00_day_03_overview.html">
     DAY 03 - Programming 101
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_03/01_python_functions_101.html">
       PYTHON FUNCTIONS 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_03/02_python_modules_101.html">
       PYTHON MODULES 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_03/03_anaconda_revisited.html">
       PYTHON ANACONDA 102
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_03/04_classes_in_python.html">
       PYTHON CLASSES 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_03/05_homework.html">
       DAY 03 - HOMEWORK
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../bootcamp/day_04/00_day_04_overview.html">
     DAY 04 - Numpy and Pandas 101
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_04/01_Numpy_data_structures.html">
       Numpy 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_04/02_Pandas_data_structures.html">
       Pandas 101
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_04/03_raw_to_tidy_with_pandas.html">
       From raw to structured
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_04/04_plotting_with_pandas.html">
       Plotting with pandas and Matplotlib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_04/05_homework.html">
       DAY 04 - HOMEWORK
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../bootcamp/day_05/00_day_05_overview.html">
     DAY 05 - Data visualisation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_05/01_visual_perception.html">
       Graphical Representations of Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../bootcamp/day_05/02_matplotlib_101.html">
       intro to matplotlib
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../about/setup.html">
   ⚙️ Course Setup
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week_01/00_overview.html">
   WEEK 01
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_01/01_reproducibility.html">
     What is Open and Reproducible Research?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_01/03_reproducibility_rules.html">
     Ten simple rules for reproducible research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_01/02_reproducibility_lab.html">
     Reproducibility lab
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week_02/00_overview.html">
   WEEK 02
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_02/02_data_cleaning_lab.html">
     DATA Cleaning 101
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_02/05_feature_engineering_lab.html">
     Feature Engineering and Feature Selection 101
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_02/03_outlier_detection_lab.html">
     We start by creating several subset datasets
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week_03/00_overview.html">
   WEEK 03
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_03/01_sklearn_101.html">
     Introducing Scikit-Learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_03/02_pca.html">
     Principal Component Analysis (PCA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_03/03_home_assignment.html">
     Home assignment
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="00_overview.html">
   WEEK 04
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Let’s cover some more basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_assessing_performance.html">
     Resampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_brainage.html">
     Home assignment : Ageing and Structural VBM
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/class/week_04/01_regression_models.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        <a class="issues-button"
            href="https://esoreq.github.io/SystemAI2022//issues/new?title=Issue%20on%20page%20%2Fclass/week_04/01_regression_models.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Let’s cover some more basics
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-regression">
     What is Regression?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#most-common-terminologies">
     Most common terminologies
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#outliers">
       Outliers:
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#model-complexity">
       Model complexity
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#why-do-we-want-to-minimizing-complexity">
       Why do we want to minimizing complexity?
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#overfitting">
       Overfitting:
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#underfitting">
       Underfitting:
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#heteroscedasticity-and-homoscedasticity">
       Heteroscedasticity and homoscedasticity
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#models-associated-with-regression-analysis">
     Models associated with regression analysis
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-we-assess-regression-performance">
     How do we assess regression performance?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#performance-measures-in-regression">
       Performance measures in regression
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#mean-absolute-error-mae">
         Mean Absolute Error (MAE)
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#mean-squared-error-mse">
         Mean Squared Error (MSE)
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#root-mean-squared-error-rmse">
         Root Mean Squared Error (RMSE)
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#median-absolute-error-mad">
         Median absolute error (MAD)
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#coefficient-of-determination-r-2-error">
         Coefficient of determination
         <span class="math notranslate nohighlight">
          \(R^2\)
         </span>
         Error
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#we-can-define-a-function-to-calculate-all-of-these-in-one-go">
       We can define a function to calculate all of these in one go
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#introduction-to-linear-regression-in-python">
     Introduction to Linear Regression in Python
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#start-with-a-simple-problem">
   Start with a simple problem
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compare-this-to-a-tree-model">
   Compare this to a tree model
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-about-non-linear-space">
     What about non-linear space?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#let-s-work-with-a-famous-model">
       Let’s work with a famous model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#our-hrf-function">
       Our hrf function
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-do-regression-trees-work-on-nonelinear-space">
   How do regression trees work on nonelinear space?
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-trees-overfit">
   Regression trees overfit
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-trees-are-a-fast-and-straightforward-way-to-understand-complex-relationships">
   regression trees are a fast and straightforward way to understand complex relationships
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#can-we-solve-non-linear-problems-with-linear-models">
     Can we solve non-linear problems with linear models?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-we-know-what-solution-to-select">
     How do we know what solution to select?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#last-algorithm-for-today">
     Last algorithm for today
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-support-vector-machine">
       the support vector machine
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lets-start-with-what-makes-svr-different-then-the-models-we-covered-so-far">
       Lets start with what makes SVR different then the models we covered so far
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#but-we-are-missing-a-big-part-of-the-equation-here">
     But we are missing a big part of the equation here
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Let’s cover some more basics</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Let’s cover some more basics
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-regression">
     What is Regression?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#most-common-terminologies">
     Most common terminologies
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#outliers">
       Outliers:
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#model-complexity">
       Model complexity
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#why-do-we-want-to-minimizing-complexity">
       Why do we want to minimizing complexity?
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#overfitting">
       Overfitting:
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#underfitting">
       Underfitting:
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#heteroscedasticity-and-homoscedasticity">
       Heteroscedasticity and homoscedasticity
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#models-associated-with-regression-analysis">
     Models associated with regression analysis
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-we-assess-regression-performance">
     How do we assess regression performance?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#performance-measures-in-regression">
       Performance measures in regression
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#mean-absolute-error-mae">
         Mean Absolute Error (MAE)
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#mean-squared-error-mse">
         Mean Squared Error (MSE)
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#root-mean-squared-error-rmse">
         Root Mean Squared Error (RMSE)
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#median-absolute-error-mad">
         Median absolute error (MAD)
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#coefficient-of-determination-r-2-error">
         Coefficient of determination
         <span class="math notranslate nohighlight">
          \(R^2\)
         </span>
         Error
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#we-can-define-a-function-to-calculate-all-of-these-in-one-go">
       We can define a function to calculate all of these in one go
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#introduction-to-linear-regression-in-python">
     Introduction to Linear Regression in Python
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#start-with-a-simple-problem">
   Start with a simple problem
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compare-this-to-a-tree-model">
   Compare this to a tree model
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-about-non-linear-space">
     What about non-linear space?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#let-s-work-with-a-famous-model">
       Let’s work with a famous model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#our-hrf-function">
       Our hrf function
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-do-regression-trees-work-on-nonelinear-space">
   How do regression trees work on nonelinear space?
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-trees-overfit">
   Regression trees overfit
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-trees-are-a-fast-and-straightforward-way-to-understand-complex-relationships">
   regression trees are a fast and straightforward way to understand complex relationships
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#can-we-solve-non-linear-problems-with-linear-models">
     Can we solve non-linear problems with linear models?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-we-know-what-solution-to-select">
     How do we know what solution to select?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#last-algorithm-for-today">
     Last algorithm for today
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-support-vector-machine">
       the support vector machine
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lets-start-with-what-makes-svr-different-then-the-models-we-covered-so-far">
       Lets start with what makes SVR different then the models we covered so far
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#but-we-are-missing-a-big-part-of-the-equation-here">
     But we are missing a big part of the equation here
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="let-s-cover-some-more-basics">
<h1>Let’s cover some more basics<a class="headerlink" href="#let-s-cover-some-more-basics" title="Permalink to this headline">¶</a></h1>
<div class="section" id="what-is-regression">
<h2>What is Regression?<a class="headerlink" href="#what-is-regression" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Regression belongs to the category of supervised learning where we model the relationship between the feature space and a continuous target variable (aka the response vector).</p></li>
<li><p>The goal of regression algorithms is to uncover a perfect relationship <span class="math notranslate nohighlight">\(f(X)=y\)</span></p></li>
<li><p>However, in reality data is noisy… therefore <span class="math notranslate nohighlight">\(f(X)= y +\epsilon\)</span></p></li>
<li><p>In Regression we use some computational method to train a model <span class="math notranslate nohighlight">\(\hat f(X) \approx f(X)\)</span>:</p>
<ul>
<li><p>Which means we try to find a mapping function <span class="math notranslate nohighlight">\(f\)</span></p></li>
<li><p>Based on some input dataset <span class="math notranslate nohighlight">\(X\)</span></p></li>
<li><p>To create continuous output value <span class="math notranslate nohighlight">\(y\)</span></p></li>
<li><p>That is close as possible to the hypothetical model <span class="math notranslate nohighlight">\(f(X)\)</span></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="most-common-terminologies">
<h2>Most common terminologies<a class="headerlink" href="#most-common-terminologies" title="Permalink to this headline">¶</a></h2>
<div class="section" id="outliers">
<h3>Outliers:<a class="headerlink" href="#outliers" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Outliers are basically values or data points that are very stray from the general population or distribution of data.</p></li>
<li><p>Outliers have the ability to skew the results of any ML model towards their detection.</p></li>
<li><p>Therefore, it is necessary to detect them early on or use algorithms resistant to outliers.</p></li>
</ul>
</div>
<div class="section" id="model-complexity">
<h3>Model complexity<a class="headerlink" href="#model-complexity" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>A model can be complex because it has many parameters/rules or many features or both</p></li>
<li><p>Our goal is to find a model that maximises some performance measure while minimizing complexity</p></li>
</ul>
</div>
<div class="section" id="why-do-we-want-to-minimizing-complexity">
<h3>Why do we want to minimizing complexity?<a class="headerlink" href="#why-do-we-want-to-minimizing-complexity" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>The more complex the model is the less interpretable it is and as a result the less insights we can derive from it</p></li>
<li><p>In general we wish to find a model that generalises well to unseen data</p></li>
<li><p>To achieve that we often rely on data-driven methods to reduce the chance of either overfitting or underfitting</p></li>
<li><p>This is reoffered to as hyperparameter tuning (in order to select the best parameters across our pipeline)</p></li>
<li><p>And feature selection or elimination to reduce the complexity of the model</p></li>
</ul>
</div>
<div class="section" id="overfitting">
<h3>Overfitting:<a class="headerlink" href="#overfitting" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Overfitting is the process of learning a bespoke model that solves the approximation problem extremely well for the training data but it has poor generalizability</p></li>
</ul>
</div>
<div class="section" id="underfitting">
<h3>Underfitting:<a class="headerlink" href="#underfitting" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Overfitting is the process of learning a bespoke model that solves the approximation problem extremely well for the training data but it has poor generalizability</p></li>
</ul>
</div>
<div class="section" id="heteroscedasticity-and-homoscedasticity">
<h3>Heteroscedasticity and homoscedasticity<a class="headerlink" href="#heteroscedasticity-and-homoscedasticity" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>This simply means the uniformity or heterogeneity of the variance around the regression line</p></li>
</ul>
</div>
</div>
<div class="section" id="models-associated-with-regression-analysis">
<h2>Models associated with regression analysis<a class="headerlink" href="#models-associated-with-regression-analysis" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>We can roughly separate any supervised model to two major classes</p>
<ul>
<li><p>Parametric models</p>
<ul>
<li><p>A parametric model is a learner that summarizes data through a fixed collection of parameters.</p></li>
</ul>
</li>
<li><p>Non-Parametric models</p>
<ul>
<li><p>A non-parametric model is a learner where the number of parameters grows with the size of the training set.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>We can also separate models based on the type of association</p>
<ul>
<li><p>Linear or Non-linear</p></li>
</ul>
</li>
<li><p>Or type of output</p>
<ul>
<li><p>Single output</p></li>
<li><p>Multiple output</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="how-do-we-assess-regression-performance">
<h2>How do we assess regression performance?<a class="headerlink" href="#how-do-we-assess-regression-performance" title="Permalink to this headline">¶</a></h2>
<div class="section" id="performance-measures-in-regression">
<h3>Performance measures in regression<a class="headerlink" href="#performance-measures-in-regression" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Recall that in regression our task is to predict a continuous value (the depndent variable)
based a set of independent variables that we assume hold some informative association to the target.</p></li>
<li><p>The various metrics we will use to evaluate regression results are</p>
<ul>
<li><p>Mean Absolute Error (MAE)</p></li>
<li><p>Mean Squared Error(MSE)</p></li>
<li><p>Root-Mean-Squared-Error(RMSE)</p></li>
<li><p>Median absolute error (MAD)</p></li>
<li><p>Coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> score</p></li>
</ul>
</li>
</ul>
<div class="section" id="mean-absolute-error-mae">
<h4>Mean Absolute Error (MAE)<a class="headerlink" href="#mean-absolute-error-mae" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>MAE is the absolute difference between the target and predicted values.</p></li>
<li><p>It is more robust to outliers compared to MSE.</p></li>
<li><p>MAE is a linear score which means all the individual differences are weighted equally.</p></li>
<li><p>One benefit of MAE is that it is simple to interpret as no transformation are done to the data.</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\text{MAE} = 1/n \sum^n_{i=1} |y_i-\hat y_i|\)</span></p>
</div>
<div class="section" id="mean-squared-error-mse">
<h4>Mean Squared Error (MSE)<a class="headerlink" href="#mean-squared-error-mse" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>MSE is one the most common metric for fitting regression models.</p></li>
<li><p>It is simply the average of the squared difference between the target predicted values.</p></li>
<li><p>Squaring the differences means the metric is sensitive even to small errors</p></li>
<li><p>This leads to over-estimation of error.</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\text{MSE} = 1/n \sum^n_{i=1} (y_i-\hat y_i)^2\)</span></p>
</div>
<div class="section" id="root-mean-squared-error-rmse">
<h4>Root Mean Squared Error (RMSE)<a class="headerlink" href="#root-mean-squared-error-rmse" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>RMSE is the most widely used metric for regression tasks</p></li>
<li><p>It is the square root of the MSE.</p></li>
<li><p>However, the errors are first squared and then avereged</p></li>
<li><p>This poses a high penalty on large errors.</p></li>
<li><p>And suggests that RMSE is most useful when large errors are undesired.</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \text{RMSE} = \sqrt{\frac{\sum^n_{i=1} (y_i-\hat y_i)^2}{n}}\)</span></p>
</div>
<div class="section" id="median-absolute-error-mad">
<h4>Median absolute error (MAD)<a class="headerlink" href="#median-absolute-error-mad" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>A robust measure of the variability of a univariate sample of quantitative data.</p></li>
<li><p>It is a more resilient error measure to outliers in a data set than the standard deviation.</p></li>
<li><p>It is easy to communicate</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\text{MAD}(y, \hat{y}) = \text{median}(\mid y_1 - \hat{y}_1 \mid, \ldots, \mid y_n - \hat{y}_n \mid).\)</span></p>
</div>
<div class="section" id="coefficient-of-determination-r-2-error">
<h4>Coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> Error<a class="headerlink" href="#coefficient-of-determination-r-2-error" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(R^2\)</span> is another metric used for evaluating the performance of a regression model</p></li>
<li><p>The <span class="math notranslate nohighlight">\(R^2\)</span> metric is used to compare a regression model with some constant baseline (usually the mean)</p></li>
<li><p>The larger the difference, between the model and the baseline the greater the value (and the better the model)</p></li>
<li><p><span class="math notranslate nohighlight">\(R^2\)</span> range is <span class="math notranslate nohighlight">\((-\infty,1)\)</span>; as a result, worse models then the mean constant will be negative</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( R^2 = 1-\frac{MSE(model)}{MSE(baseline)}\)</span></p>
</div>
</div>
<div class="section" id="we-can-define-a-function-to-calculate-all-of-these-in-one-go">
<h3>We can define a function to calculate all of these in one go<a class="headerlink" href="#we-can-define-a-function-to-calculate-all-of-these-in-one-go" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Given some ground truth y and some approximation y_hat we want a function that will report all the different performance metrics of interest</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span><span class="n">mean_squared_error</span><span class="p">,</span><span class="n">r2_score</span><span class="p">,</span><span class="n">median_absolute_error</span>
<span class="k">def</span> <span class="nf">calc_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">i</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">):</span>
    <span class="n">err</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Kind&#39;</span><span class="p">:</span><span class="n">kind</span><span class="p">,</span>
            <span class="s1">&#39;MAE&#39;</span><span class="p">:</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">),</span>
            <span class="s1">&#39;MSE&#39;</span><span class="p">:</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">),</span>
            <span class="s1">&#39;MAD&#39;</span><span class="p">:</span><span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">),</span>
            <span class="s1">&#39;RMSE&#39;</span><span class="p">:</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="c1"># If True returns MSE value, if False returns RMSE value.</span>
            <span class="s1">&#39;r2&#39;</span><span class="p">:</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">)}</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">err</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="introduction-to-linear-regression-in-python">
<h2>Introduction to Linear Regression in Python<a class="headerlink" href="#introduction-to-linear-regression-in-python" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Linear regression is one of the most basic predictive models it uses features data to estimate a response variable.</p></li>
<li><p>It is considered the first step in any predictive modelling effort</p></li>
<li><p>The basic idea is that we can find some weighted association between the features and output.</p></li>
</ul>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="start-with-a-simple-problem">
<h1>Start with a simple problem<a class="headerlink" href="#start-with-a-simple-problem" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>let’s start with a linear problem with one feature and one response vector <span class="math notranslate nohighlight">\( y = 0.5x+\epsilon \)</span></p></li>
<li><p>We will use a linear model to fit a line onto the toy observation</p></li>
<li><p>Recall from your statistics courses over the year the simple linear model <span class="math notranslate nohighlight">\( Y=a+\beta X+\epsilon\)</span></p></li>
<li><p>What we have here is a robust predictive framework</p>
<ul>
<li><p>Let’s refresh your memory with the intuition behind this formula</p></li>
<li><p>a is called the intercept, and it merely means some constant baseline to shift the parametric space</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta\)</span> is the weight we are multiplying X with to match Y as best as possible</p></li>
<li><p>finally <span class="math notranslate nohighlight">\(\epsilon\)</span> is the deviation or error between the product of the
function and actual value of Y we are trying to predict</p></li>
</ul>
</li>
<li><p>The stronger the association between y (the continuous response vector) and X
the easier it is to fit a line (with only two parameters) that will minimise the error</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">2022</span><span class="p">)</span>
<span class="n">fu</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">noise</span><span class="p">:</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">noise</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,))</span>
<span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">fu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># ground truth </span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">perf</span> <span class="o">=</span> <span class="p">[]</span> 
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">sd</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">)):</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">fu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">sd</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">polyval</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_range</span><span class="p">)</span> <span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ground truth&#39;</span><span class="p">);</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">polyval</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">x_range</span><span class="p">)</span> <span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;linear model&#39;</span><span class="p">);</span>

    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;$y = </span><span class="si">{</span><span class="n">coefs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">+</span><span class="si">{</span><span class="n">coefs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">*x +\epsilon$&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">perf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calc_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="sa">f</span><span class="s1">&#39;err=</span><span class="si">{</span><span class="n">sd</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">perf</span><span class="p">)</span>    
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">Input In [3],</span> in <span class="ni">&lt;cell line: 4&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>     <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;$y = </span><span class="si">{</span><span class="n">coefs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">+</span><span class="si">{</span><span class="n">coefs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">*x +\epsilon$&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span>     <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="ne">---&gt; </span><span class="mi">13</span>     <span class="n">perf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calc_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="sa">f</span><span class="s1">&#39;err=</span><span class="si">{</span><span class="n">sd</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">perf</span><span class="p">)</span>

<span class="nn">Input In [1],</span> in <span class="ni">calc_error</span><span class="nt">(y, y_hat, i, kind)</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="k">def</span> <span class="nf">calc_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">i</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">):</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>     <span class="n">err</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Kind&#39;</span><span class="p">:</span><span class="n">kind</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>             <span class="s1">&#39;MAE&#39;</span><span class="p">:</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">),</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span>             <span class="s1">&#39;MSE&#39;</span><span class="p">:</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">),</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span>             <span class="s1">&#39;MAD&#39;</span><span class="p">:</span><span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">),</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>             <span class="s1">&#39;RMSE&#39;</span><span class="p">:</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="c1"># If True returns MSE value, if False returns RMSE value.</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>             <span class="s1">&#39;r2&#39;</span><span class="p">:</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">)}</span>
<span class="ne">----&gt; </span><span class="mi">9</span>     <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">err</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="ne">NameError</span>: name &#39;pd&#39; is not defined
</pre></div>
</div>
<img alt="../../_images/01_regression_models_7_1.png" src="../../_images/01_regression_models_7_1.png" />
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="compare-this-to-a-tree-model">
<h1>Compare this to a tree model<a class="headerlink" href="#compare-this-to-a-tree-model" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>The Decision Tree Classifier predicts the regressed value
based on a set of local rules that become more specific as the tree grows deeper</p></li>
<li><p>This heuristic is called recursive partitioning, and the goal is to iteratively
uncover a set of rules/splits that divide the feature space based on local patterns</p></li>
<li><p>The recursive divisions will continue until all leaves have been visited or
some stopping criteria have been reached</p></li>
<li><p>The tree model offers a crude simplified solution to the regression problem</p></li>
<li><p><a class="reference external" href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">Understanding Machine Learning: From Theory to Algorithms - ch18</a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span><span class="p">,</span><span class="n">plot_tree</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">noise</span><span class="p">:</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">noise</span><span class="o">*</span><span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">perf</span> <span class="o">=</span> <span class="p">[]</span> 

<span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">sd</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">)):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">fu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">sd</span><span class="p">)</span>
    <span class="n">mdl</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span><span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_range</span><span class="p">)</span> <span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ground truth&#39;</span><span class="p">);</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">polyval</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_range</span><span class="p">)</span> <span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ground truth&#39;</span><span class="p">);</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">perf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calc_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="sa">f</span><span class="s1">&#39;err=</span><span class="si">{</span><span class="n">sd</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">perf</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Kind</th>
      <th>MAE</th>
      <th>MSE</th>
      <th>MAD</th>
      <th>RMSE</th>
      <th>r2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>err=1</td>
      <td>4.572925</td>
      <td>31.822150</td>
      <td>3.824980</td>
      <td>5.641112</td>
      <td>-5.336461</td>
    </tr>
    <tr>
      <th>1</th>
      <td>err=3</td>
      <td>4.116997</td>
      <td>27.457780</td>
      <td>3.523919</td>
      <td>5.240017</td>
      <td>-3.234762</td>
    </tr>
    <tr>
      <th>2</th>
      <td>err=5</td>
      <td>3.950589</td>
      <td>25.384741</td>
      <td>3.469278</td>
      <td>5.038327</td>
      <td>-2.275628</td>
    </tr>
    <tr>
      <th>3</th>
      <td>err=7</td>
      <td>4.208337</td>
      <td>28.485265</td>
      <td>3.822363</td>
      <td>5.337159</td>
      <td>-1.409640</td>
    </tr>
    <tr>
      <th>4</th>
      <td>err=9</td>
      <td>3.662073</td>
      <td>22.778036</td>
      <td>2.491821</td>
      <td>4.772634</td>
      <td>-1.064681</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../_images/01_regression_models_9_1.png" src="../../_images/01_regression_models_9_1.png" />
</div>
</div>
<div class="section" id="what-about-non-linear-space">
<h2>What about non-linear space?<a class="headerlink" href="#what-about-non-linear-space" title="Permalink to this headline">¶</a></h2>
<div class="section" id="let-s-work-with-a-famous-model">
<h3>Let’s work with a famous model<a class="headerlink" href="#let-s-work-with-a-famous-model" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>In this 2D regression example, we will use the Haemodynamic Response Function <a class="reference external" href="https://www.fil.ion.ucl.ac.uk/~karl/Nonlinear%20event%20related%20responses.pdf">(HRF) mixture of gammas</a>
as our non-linear regression data generator</p></li>
<li><p>The idea is simple, and you probably covered this in many courses:</p>
<ul class="simple">
<li><p>The canonical haemodynamic response function (HRF)} defines the typical response
of the neurovascular system (as reflected by the MR signal in a noiseless environment)
to a brief, intense period of neural stimulation.</p></li>
<li><p>With an initial overshoot response followed by a poststimulus undershoot.
It is commonly represented as a mixture of gamma probability density functions in the following form:</p></li>
</ul>
</li>
<li><div class="math notranslate nohighlight">
\[H(x) = \frac{l_1^{h_1} x^{h_1 - 1} e^{-l_1 x}}{\Gamma(h_1)}-r\frac{l_2^{h_2} x^{h_2 - 1} e^{-l_2 x}}{\Gamma(h_2)}\]</div>
</li>
<li><p>where <span class="math notranslate nohighlight">\(\Gamma\)</span> is the gamma function with <span class="math notranslate nohighlight">\(l, h\)</span> as the scale and shape parameters, respectively,
and <span class="math notranslate nohighlight">\(r\)</span> defines the ratio of response to undershoot.</p></li>
</ul>
</div>
<div class="section" id="our-hrf-function">
<h3>Our hrf function<a class="headerlink" href="#our-hrf-function" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>We defined the first peak at 6 seconds and the delay of undershoot has its minima at 16 seconds</p></li>
<li><p>We also defined r as 1/6</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">gamma</span>
<span class="k">def</span> <span class="nf">sample_hrf</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span><span class="n">noise_ratio</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">==</span><span class="nb">int</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>                  
    <span class="n">Y</span> <span class="o">=</span>  <span class="n">gamma</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span> <span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">-</span><span class="n">gamma</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span> <span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">/</span><span class="mi">6</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">noise_ratio</span><span class="p">:</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">noise_ratio</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,),</span><span class="n">X</span>  
<span class="n">yn</span><span class="p">,</span><span class="n">Xn</span> <span class="o">=</span> <span class="n">sample_hrf</span><span class="p">(</span><span class="n">noise_ratio</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>   
<span class="n">Y</span><span class="p">,</span><span class="n">X</span> <span class="o">=</span> <span class="n">sample_hrf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">))</span>  
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xn</span><span class="p">,</span> <span class="n">yn</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;lightgray&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">32</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="s1">&#39;--r&#39;</span><span class="p">);</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_regression_models_11_0.png" src="../../_images/01_regression_models_11_0.png" />
</div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="how-do-regression-trees-work-on-nonelinear-space">
<h1>How do regression trees work on nonelinear space?<a class="headerlink" href="#how-do-regression-trees-work-on-nonelinear-space" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Regression trees and classification trees work in a similar way</p></li>
<li><p>They divide the dataspace and create local rules that can be applied to new events</p></li>
<li><p>How would you describe the HRF textually?</p></li>
<li><p>A simple tree would look like this:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>    <span class="p">|</span>--- <span class="k">if</span> x &lt;<span class="o">=</span> <span class="m">10</span>
    <span class="p">|</span>   <span class="p">|</span>--- and <span class="k">if</span> x &lt;<span class="o">=</span> <span class="m">2</span>
    <span class="p">|</span>   <span class="p">|</span>   <span class="p">|</span>--- <span class="nv">y</span> <span class="o">=</span> <span class="m">0</span>
    <span class="p">|</span>   <span class="p">|</span>--- <span class="k">else</span> 
    <span class="p">|</span>   <span class="p">|</span>   <span class="p">|</span>--- <span class="nv">y</span> <span class="o">=</span> <span class="m">0</span>.2
    <span class="p">|</span>--- <span class="k">else</span> &gt;  <span class="m">10</span>
    <span class="p">|</span>   <span class="p">|</span>--- and <span class="k">if</span> x &lt;<span class="o">=</span> <span class="m">12</span>
    <span class="p">|</span>   <span class="p">|</span>   <span class="p">|</span>--- y: <span class="m">0</span>.05
    <span class="p">|</span>   <span class="p">|</span>--- <span class="k">else</span>
    <span class="p">|</span>   <span class="p">|</span>   <span class="p">|</span>--- y: -0.01
</pre></div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="regression-trees-overfit">
<h1>Regression trees overfit<a class="headerlink" href="#regression-trees-overfit" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Like all instance based modles they are prune to overfitting</p></li>
<li><p>Let’s try to visualize the idea of overfitting using the HRF</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span><span class="p">,</span><span class="n">plot_tree</span>
<span class="kn">import</span> <span class="nn">matplotlib.gridspec</span> <span class="k">as</span> <span class="nn">gridspec</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">)</span>
<span class="n">x_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">perf</span> <span class="o">=</span> <span class="p">[]</span> 

<span class="k">for</span> <span class="n">ix</span><span class="p">,</span><span class="n">degree</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)):</span>
    <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">ix</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])</span>
    <span class="n">mdl</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">degree</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xn</span><span class="p">,</span><span class="n">yn</span><span class="p">)</span>  
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_plot</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xn</span><span class="p">,</span> <span class="n">yn</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;lightgrey&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>  
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ground Truth&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">),</span> <span class="n">y_hat</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fitted model&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
    <span class="n">perf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calc_error</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span><span class="n">yn</span><span class="p">,</span><span class="n">ix</span><span class="p">,</span><span class="sa">f</span><span class="s1">&#39;max_depth=</span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">perf</span><span class="p">)</span>     
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Kind</th>
      <th>MAE</th>
      <th>MSE</th>
      <th>MAD</th>
      <th>RMSE</th>
      <th>r2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>max_depth=1</td>
      <td>0.029474</td>
      <td>0.001594</td>
      <td>0.020439</td>
      <td>0.039919</td>
      <td>0.076251</td>
    </tr>
    <tr>
      <th>1</th>
      <td>max_depth=2</td>
      <td>0.022506</td>
      <td>0.000876</td>
      <td>0.017173</td>
      <td>0.029601</td>
      <td>0.641239</td>
    </tr>
    <tr>
      <th>2</th>
      <td>max_depth=3</td>
      <td>0.017762</td>
      <td>0.000523</td>
      <td>0.014549</td>
      <td>0.022874</td>
      <td>0.812819</td>
    </tr>
    <tr>
      <th>3</th>
      <td>max_depth=4</td>
      <td>0.016403</td>
      <td>0.000445</td>
      <td>0.013451</td>
      <td>0.021100</td>
      <td>0.845061</td>
    </tr>
    <tr>
      <th>4</th>
      <td>max_depth=5</td>
      <td>0.015169</td>
      <td>0.000387</td>
      <td>0.012591</td>
      <td>0.019682</td>
      <td>0.867838</td>
    </tr>
    <tr>
      <th>5</th>
      <td>max_depth=6</td>
      <td>0.013856</td>
      <td>0.000347</td>
      <td>0.011015</td>
      <td>0.018620</td>
      <td>0.883339</td>
    </tr>
    <tr>
      <th>6</th>
      <td>max_depth=7</td>
      <td>0.012803</td>
      <td>0.000306</td>
      <td>0.009805</td>
      <td>0.017504</td>
      <td>0.898284</td>
    </tr>
    <tr>
      <th>7</th>
      <td>max_depth=8</td>
      <td>0.011266</td>
      <td>0.000257</td>
      <td>0.007956</td>
      <td>0.016040</td>
      <td>0.915954</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../_images/01_regression_models_13_1.png" src="../../_images/01_regression_models_13_1.png" />
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="regression-trees-are-a-fast-and-straightforward-way-to-understand-complex-relationships">
<h1>regression trees are a fast and straightforward way to understand complex relationships<a class="headerlink" href="#regression-trees-are-a-fast-and-straightforward-way-to-understand-complex-relationships" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>We can also visually explore the ruleset of the tree</p></li>
<li><p>The information in the graph reflects the model’s decision space</p></li>
<li><p>The top node is called the root of the tree</p>
<ul>
<li><p>The top value reflects the split rule (in this case a threshold point) As you can see 152 samples are above 9.215 and 348 are below</p></li>
<li><p>MSE stands for mean, standard error and is a common way to estimate regression models (however there are many other ways)</p></li>
<li><p>Finally, the value represents the predicted value the tree will assign a point</p></li>
<li><p>for example, if we take x=6 it will take us in the following path:</p>
<ul>
<li><p>left (6&lt;9.8), right (6&gt;2.023),  left (6&lt;7.723), right ( 6&gt;3.25)</p></li>
<li><p>our path will end there, and we will be assigned a value of 0.151</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mdl</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xn</span><span class="p">,</span><span class="n">yn</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">mdl</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_regression_models_15_0.png" src="../../_images/01_regression_models_15_0.png" />
</div>
</div>
<div class="section" id="can-we-solve-non-linear-problems-with-linear-models">
<h2>Can we solve non-linear problems with linear models?<a class="headerlink" href="#can-we-solve-non-linear-problems-with-linear-models" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>We can a concept called Polynomial expansion to capture non-linear properties</p></li>
<li><p>As you can see a 9th polynomial is fitted pretty good</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">import</span> <span class="nn">matplotlib.gridspec</span> <span class="k">as</span> <span class="nn">gridspec</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">)</span>
<span class="n">x_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">perf</span> <span class="o">=</span> <span class="p">[]</span> 
<span class="k">for</span> <span class="n">ix</span><span class="p">,</span><span class="n">degree</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">2</span><span class="p">)):</span>
    <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">ix</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])</span>
    <span class="n">pf</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span>
    <span class="n">xx</span> <span class="o">=</span> <span class="n">pf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Xn</span><span class="p">)</span>
    <span class="n">mdl</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yn</span><span class="p">)</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">pf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_plot</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xn</span><span class="p">,</span> <span class="n">yn</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;lightgray&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fitted model&#39;</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ground Truth&#39;</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Polynom degree=</span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s2"> (dim=</span><span class="si">{</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">perf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calc_error</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xx</span><span class="p">),</span><span class="n">yn</span><span class="p">,</span><span class="n">ix</span><span class="p">,</span><span class="sa">f</span><span class="s1">&#39;max_depth=</span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
<span class="n">perf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">perf</span><span class="p">)</span>     
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_regression_models_17_0.png" src="../../_images/01_regression_models_17_0.png" />
</div>
</div>
</div>
<div class="section" id="how-do-we-know-what-solution-to-select">
<h2>How do we know what solution to select?<a class="headerlink" href="#how-do-we-know-what-solution-to-select" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Is there a better way of selecting a model</p></li>
<li><p>Perhaps something like the scree plot idea from last week?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>

<span class="n">x_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">perf</span> <span class="o">=</span> <span class="p">[]</span> 
<span class="k">for</span> <span class="n">ix</span><span class="p">,</span><span class="n">degree</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">18</span><span class="p">)):</span>
    <span class="n">pf</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span>
    <span class="n">xx</span> <span class="o">=</span> <span class="n">pf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Xn</span><span class="p">)</span>
    <span class="n">mdl</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yn</span><span class="p">)</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
    <span class="n">perf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calc_error</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span><span class="n">yn</span><span class="p">,</span><span class="n">ix</span><span class="p">,</span><span class="sa">f</span><span class="s1">&#39;poly_order=</span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
<span class="n">perf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">perf</span><span class="p">)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">perf</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">perf</span><span class="p">[</span><span class="n">metrics</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
    <span class="n">func</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;argmax&#39;</span><span class="p">,</span><span class="s1">&#39;max&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">metrics</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;r2&#39;</span> <span class="k">else</span> <span class="p">[</span><span class="s1">&#39;argmin&#39;</span><span class="p">,</span><span class="s1">&#39;min&#39;</span><span class="p">]</span>
    <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">perf</span><span class="p">[</span><span class="n">metrics</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;r*&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;$</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s1"> = </span><span class="si">{</span><span class="n">y</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">$ &#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_regression_models_19_0.png" src="../../_images/01_regression_models_19_0.png" />
</div>
</div>
</div>
<div class="section" id="last-algorithm-for-today">
<h2>Last algorithm for today<a class="headerlink" href="#last-algorithm-for-today" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-support-vector-machine">
<h3>the support vector machine<a class="headerlink" href="#the-support-vector-machine" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>To illustrate this point and introduce our final algorithm for today</p></li>
<li><p>Support Vector Machine constructs a hyperplane or list of hyperplanes in high dimensional space, which are then used for classification/regression tasks or other tasks like outlier detection.</p></li>
</ul>
</div>
<div class="section" id="lets-start-with-what-makes-svr-different-then-the-models-we-covered-so-far">
<h3>Lets start with what makes SVR different then the models we covered so far<a class="headerlink" href="#lets-start-with-what-makes-svr-different-then-the-models-we-covered-so-far" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>SVR tries to fit the best line (or hyperplane for multidimensional datasets) within a threshold value</p></li>
<li><p>In SVR, the best fit line is the hyperplane that has the maximum number of points.</p></li>
<li><p>The constant C is the box constraint, a positive numeric value that controls the penalty imposed on observations that lie outside the epsilon margin (ε) and helps to prevent overfitting (regularization).</p></li>
<li><p>This value determines the trade-off between the flatness of f(x) and the amount up to which deviations larger than ε are tolerated.</p></li>
<li><p>The threshold value is the distance between the hyperplane and boundary line.</p></li>
<li><p>The boundary is defined using a margin of tolerance epsilon</p></li>
<li><p><a class="reference external" href="https://link.springer.com/article/10.1023/B:STCO.0000035301.49549.88">The math behind support vector regression</a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
 
<span class="n">perf</span> <span class="o">=</span> <span class="p">[]</span> 
<span class="n">x_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">noise</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.06</span><span class="p">,</span><span class="mf">0.01</span><span class="p">)):</span>
    <span class="n">yn</span><span class="p">,</span><span class="n">Xn</span> <span class="o">=</span> <span class="n">sample_hrf</span><span class="p">(</span><span class="n">noise_ratio</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xn</span><span class="p">,</span> <span class="n">yn</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;lightgray&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">);</span>   
    <span class="n">mdl</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span><span class="n">C</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xn</span><span class="p">,</span><span class="n">yn</span><span class="p">)</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xn</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">db</span> <span class="ow">in</span> <span class="p">[</span><span class="o">-</span><span class="n">mdl</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">mdl</span><span class="o">.</span><span class="n">epsilon</span><span class="p">]:</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span><span class="n">mdl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_plot</span><span class="p">)</span><span class="o">+</span><span class="n">db</span> <span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;SVR</span><span class="si">{</span><span class="n">db</span><span class="si">:</span><span class="s1">02</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">);</span>
    <span class="n">perf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calc_error</span><span class="p">(</span><span class="n">yn</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="sa">f</span><span class="s1">&#39;SVR=</span><span class="si">{</span><span class="n">sd</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">perf</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Kind</th>
      <th>MAE</th>
      <th>MSE</th>
      <th>MAD</th>
      <th>RMSE</th>
      <th>r2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SVR=9</td>
      <td>0.009008</td>
      <td>0.000123</td>
      <td>0.008184</td>
      <td>0.011105</td>
      <td>0.961326</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SVR=9</td>
      <td>0.016961</td>
      <td>0.000450</td>
      <td>0.014489</td>
      <td>0.021222</td>
      <td>0.883310</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SVR=9</td>
      <td>0.024012</td>
      <td>0.000928</td>
      <td>0.020124</td>
      <td>0.030460</td>
      <td>0.743802</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SVR=9</td>
      <td>0.031198</td>
      <td>0.001521</td>
      <td>0.026646</td>
      <td>0.039004</td>
      <td>0.703034</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SVR=9</td>
      <td>0.040813</td>
      <td>0.002594</td>
      <td>0.033908</td>
      <td>0.050929</td>
      <td>0.541551</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../_images/01_regression_models_21_1.png" src="../../_images/01_regression_models_21_1.png" />
</div>
</div>
</div>
</div>
<div class="section" id="but-we-are-missing-a-big-part-of-the-equation-here">
<h2>But we are missing a big part of the equation here<a class="headerlink" href="#but-we-are-missing-a-big-part-of-the-equation-here" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>All of these toy examples looked at optimal solutions where the data was the same</p></li>
<li><p>This is exactly the definition of data leakage</p></li>
<li><p>How do we account for that?</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./class/week_04"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="00_overview.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">WEEK 04</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="02_assessing_performance.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Resampling</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Eyal Soreq<br/>
    
        &copy; Copyright 2021.<br/>
      <div class="extra_footer">
        <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>